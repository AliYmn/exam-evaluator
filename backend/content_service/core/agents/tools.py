"""
LangChain tools for exam evaluation agent
"""

from typing import Dict, Any, List
from langchain_core.tools import tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

from libs.settings import settings
from .models import AnswerKeyOutput, StudentAnswersOutput, EvaluationResult, PerformanceAnalysis, QualityCheckResult


@tool
def parse_answer_key_tool(pdf_text: str) -> Dict[str, Any]:
    """
    Parse answer key PDF and extract questions and answers.

    Args:
        pdf_text: Raw text extracted from PDF

    Returns:
        Dictionary with questions, total_questions, and max_possible_score
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=settings.GEMINI_API_KEY,
        temperature=0.0,  # ZERO creativity - exact copying only
        max_output_tokens=8192,
    )

    parser = JsonOutputParser(pydantic_object=AnswerKeyOutput)

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """You are a TEXT EXTRACTION tool, NOT an AI assistant. Your ONLY job is EXACT VERBATIM COPY.

ðŸš¨ CRITICAL - READ CAREFULLY:
You are FORBIDDEN from:
âŒ Paraphrasing or rewording ANY text
âŒ Summarizing or condensing content
âŒ "Improving" or "clarifying" text
âŒ Translating or changing language
âŒ Adding your own interpretations
âŒ Fixing grammar or typos in the original
âŒ Omitting ANY words, sentences, or details

You MUST:
âœ… Copy EVERY SINGLE WORD exactly as written
âœ… Preserve ALL punctuation marks (commas, periods, etc.)
âœ… Keep ALL formatting (line breaks, bullet points, numbering)
âœ… Include ALL examples, formulas, and explanations
âœ… Maintain exact spelling (even if it has typos)
âœ… Copy question numbers EXACTLY as shown (1, 2, 3 or a, b, c, etc.)

EXAMPLE:
Original: "Fotosentez nedir? Bitkilerin gÃ¼neÅŸ Ä±ÅŸÄ±ÄŸÄ±nÄ± kullanarak glikoz Ã¼retme sÃ¼recidir."
âŒ WRONG: "Fotosentez, bitkilerin Ä±ÅŸÄ±ÄŸÄ± kullanarak ÅŸeker Ã¼retmesidir."
âœ… CORRECT: "Fotosentez nedir? Bitkilerin gÃ¼neÅŸ Ä±ÅŸÄ±ÄŸÄ±nÄ± kullanarak glikoz Ã¼retme sÃ¼recidir."

Think of yourself as a COPY-PASTE function, NOT a writer.

{format_instructions}

RETURN ONLY THE JSON. ZERO INTERPRETATION.""",
            ),
            ("user", "Extract the following text VERBATIM (word-for-word):\n\n{pdf_text}"),
        ]
    )

    chain = (
        {"pdf_text": lambda x: x, "format_instructions": lambda _: parser.get_format_instructions()}
        | prompt
        | llm
        | parser
    )

    try:
        result = chain.invoke(pdf_text)

        # Ensure all questions have required fields
        for q in result["questions"]:
            if "max_score" not in q:
                q["max_score"] = 10
            if "keywords" not in q:
                q["keywords"] = []

        # Calculate totals if missing
        if "total_questions" not in result:
            result["total_questions"] = len(result["questions"])
        if "max_possible_score" not in result:
            result["max_possible_score"] = sum(q.get("max_score", 10) for q in result["questions"])

        return result
    except Exception as e:
        return {"error": str(e), "questions": [], "total_questions": 0, "max_possible_score": 0}


@tool
def parse_student_answer_tool(pdf_text: str, question_count: int) -> List[Dict[str, Any]]:
    """
    Parse student answer sheet and extract student responses.

    Args:
        pdf_text: Raw text extracted from student PDF
        question_count: Expected number of questions

    Returns:
        List of student answers with question numbers
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=settings.GEMINI_API_KEY,
        temperature=0.0,  # ZERO creativity - exact copying only
        max_output_tokens=8192,
    )

    parser = JsonOutputParser(pydantic_object=StudentAnswersOutput)

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """You are a TEXT EXTRACTION tool, NOT an AI assistant. Your ONLY job is EXACT VERBATIM COPY of student answers.

ðŸš¨ CRITICAL - READ CAREFULLY:
You are FORBIDDEN from:
âŒ Paraphrasing or rewording ANY text
âŒ Summarizing student answers
âŒ "Improving" or "clarifying" student text
âŒ Fixing student's grammar or spelling errors
âŒ Adding your own interpretations
âŒ Omitting ANY words or sentences

You MUST:
âœ… Copy EVERY SINGLE WORD the student wrote
âœ… Preserve ALL punctuation marks
âœ… Keep ALL formatting (line breaks, bullet points)
âœ… Include ALL examples and explanations student provided
âœ… Maintain exact spelling (even student's mistakes)
âœ… Copy question numbers EXACTLY as shown
âœ… If question has NO answer, write: "[No answer provided]"

EXAMPLE:
Student wrote: "Fotosentes bitkinin gunes ile gida yapmasidir."
âŒ WRONG: "Fotosentez, bitkilerin gÃ¼neÅŸ ile gÄ±da yapmasÄ±dÄ±r." (you corrected it!)
âœ… CORRECT: "Fotosentes bitkinin gunes ile gida yapmasidir." (exact copy with student's mistakes)

Think of yourself as a COPY-PASTE function, NOT a grader or writer.

EXPECTED NUMBER OF QUESTIONS: {question_count}

{format_instructions}

RETURN ONLY THE JSON. ZERO INTERPRETATION. EXACT COPY ONLY.""",
            ),
            ("user", "Extract the student's answers VERBATIM (word-for-word):\n\n{pdf_text}"),
        ]
    )

    chain = (
        {
            "pdf_text": lambda x: x["pdf_text"],
            "question_count": lambda x: x["question_count"],
            "format_instructions": lambda _: parser.get_format_instructions(),
        }
        | prompt
        | llm
        | parser
    )

    try:
        result = chain.invoke({"pdf_text": pdf_text, "question_count": question_count})
        return result.get("answers", [])
    except Exception:
        return [{"number": i + 1, "student_answer": "[Error parsing]"} for i in range(question_count)]


@tool
def evaluate_answer_tool(
    question_number: int,
    question_text: str,
    expected_answer: str,
    student_answer: str,
    max_score: float,
    keywords: str = "",
) -> Dict[str, Any]:
    """
    Evaluate a single student answer against the expected answer.
    NOW WITH CONFIDENCE SCORE!

    Args:
        question_number: Question number
        question_text: The question text
        expected_answer: Expected answer from answer key
        student_answer: Student's actual answer
        max_score: Maximum score possible
        keywords: Key concepts to look for (comma-separated)

    Returns:
        Dictionary with score, feedback, is_correct, confidence, and reasoning
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=settings.GEMINI_API_KEY,
        temperature=0.2,
        max_output_tokens=2048,
    )

    parser = JsonOutputParser(pydantic_object=EvaluationResult)

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """Sen bir uzman sÄ±nav deÄŸerlendiricisisin. GÃ¶revin Ã¶ÄŸrencinin cevabÄ±nÄ± adil bir ÅŸekilde deÄŸerlendirmektir.

DEÄžERLENDÄ°RME KRÄ°TERLERÄ°:
1. DoÄŸruluk: Cevap beklenen cevapla eÅŸleÅŸiyor mu?
2. TamlÄ±k: TÃ¼m ana noktalar kapsanmÄ±ÅŸ mÄ±?
3. Kesinlik: Bilgiler gerÃ§eklere uygun mu?
4. AÃ§Ä±klÄ±k: Cevap iyi aÃ§Ä±klanmÄ±ÅŸ mÄ±?

PUANLAMA REHBERÄ°:
- %90-100: MÃ¼kemmel, tÃ¼m noktalar doÄŸru ÅŸekilde ele alÄ±nmÄ±ÅŸ
- %70-89: Ä°yi, Ã§oÄŸu nokta kÃ¼Ã§Ã¼k eksiklerle ele alÄ±nmÄ±ÅŸ
- %50-69: Yeterli, bazÄ± anahtar noktalar eksik
- %30-49: KÄ±smi anlayÄ±ÅŸ
- %0-29: YanlÄ±ÅŸ veya yetersiz

GÃœVENÄ°LÄ°RLÄ°K SKORU (confidence):
- 0.9-1.0: Ã‡ok emin (net doÄŸru/yanlÄ±ÅŸ cevap)
- 0.7-0.9: Emin (objektif deÄŸerlendirme mÃ¼mkÃ¼n)
- 0.5-0.7: Orta gÃ¼ven (subjektif unsurlar var)
- 0.0-0.5: DÃ¼ÅŸÃ¼k gÃ¼ven (belirsiz, insan kontrolÃ¼ gerekebilir)

{format_instructions}

ADÄ°L ve YAPICI ol. EÄŸer Ã¶ÄŸrenci cevabÄ± "[No answer provided]" ise, 0 puan ver.
FEEDBACK ve REASONING MUTLAKA TÃœRKÃ‡E OLMALIDIR.""",
            ),
            (
                "user",
                """SORU #{question_number}:
{question_text}

BEKLENÄ°LEN CEVAP (Cevap AnahtarÄ±):
{expected_answer}

Ã–ÄžRENCÄ°NÄ°N CEVABI:
{student_answer}

ARANACAK ANAHTAR KAVRAMLAR: {keywords}
MAKSÄ°MUM PUAN: {max_score}

Ã‡IKTI Ä°Ã‡ERMELÄ°:
- score: Verilen puan
- feedback: TÃ¼rkÃ§e aÃ§Ä±klama
- is_correct: DoÄŸru mu?
- confidence: GÃ¼ven skoru (0-1)
- reasoning: KÄ±sa gerekÃ§e (TÃ¼rkÃ§e)""",
            ),
        ]
    )

    chain = (
        {
            "question_number": lambda x: x["question_number"],
            "question_text": lambda x: x["question_text"],
            "expected_answer": lambda x: x["expected_answer"],
            "student_answer": lambda x: x["student_answer"],
            "keywords": lambda x: x["keywords"],
            "max_score": lambda x: x["max_score"],
            "format_instructions": lambda _: parser.get_format_instructions(),
        }
        | prompt
        | llm
        | parser
    )

    try:
        input_data = {
            "question_number": question_number,
            "question_text": question_text,
            "expected_answer": expected_answer,
            "student_answer": student_answer,
            "keywords": keywords,
            "max_score": max_score,
        }
        result = chain.invoke(input_data)

        # Ensure score is within bounds
        result["score"] = min(max(result["score"], 0), max_score)

        # Ensure required fields
        if "is_correct" not in result:
            result["is_correct"] = result["score"] >= (max_score * 0.7)
        if "confidence" not in result:
            result["confidence"] = 0.8  # Default confidence
        if "reasoning" not in result:
            result["reasoning"] = "Standart deÄŸerlendirme"

        return result
    except Exception as e:
        return {
            "score": 0,
            "feedback": f"DeÄŸerlendirme hatasÄ±: {str(e)}",
            "is_correct": False,
            "confidence": 0.0,
            "reasoning": "Hata oluÅŸtu",
        }


@tool
def quality_check_tool(evaluation_data: Dict[str, Any], max_score: float) -> Dict[str, Any]:
    """
    NEW TOOL: Quality check / self-correction for evaluations.
    Reviews the evaluation to ensure it's fair and accurate.

    Args:
        evaluation_data: The evaluation result to check
        max_score: Maximum possible score

    Returns:
        Quality check result with is_acceptable, issues, and suggested_corrections
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=settings.GEMINI_API_KEY,
        temperature=0.1,
        max_output_tokens=1024,
    )

    parser = JsonOutputParser(pydantic_object=QualityCheckResult)

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """Sen bir kalite kontrol uzmanÄ±sÄ±n. GÃ¶revin sÄ±nav deÄŸerlendirmelerinin adil ve tutarlÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol etmek.

KONTROL KRÄ°TERLERÄ°:
1. Puan feedback ile uyumlu mu?
2. Puan aralÄ±ÄŸÄ± mantÄ±klÄ± mÄ±? (0 ile max_score arasÄ±)
3. Feedback yeterince aÃ§Ä±klayÄ±cÄ± mÄ±?
4. Puanlama rehberine uyuluyor mu?

KABUL EDÄ°LEBÄ°LÄ°R DEÄžÄ°L ise issues listesinde belirt.

{format_instructions}""",
            ),
            (
                "user",
                """DEÄžERLENDÄ°RME KONTROL:

Verilen Puan: {score}/{max_score}
Feedback: {feedback}
Confidence: {confidence}
Reasoning: {reasoning}

Bu deÄŸerlendirme kaliteli ve adil mi?""",
            ),
        ]
    )

    chain = (
        {
            "score": lambda x: x["score"],
            "max_score": lambda x: x["max_score"],
            "feedback": lambda x: x["feedback"],
            "confidence": lambda x: x.get("confidence", 0.8),
            "reasoning": lambda x: x.get("reasoning", "Yok"),
            "format_instructions": lambda _: parser.get_format_instructions(),
        }
        | prompt
        | llm
        | parser
    )

    try:
        input_data = {
            "score": evaluation_data.get("score", 0),
            "max_score": max_score,
            "feedback": evaluation_data.get("feedback", ""),
            "confidence": evaluation_data.get("confidence", 0.8),
            "reasoning": evaluation_data.get("reasoning", "Yok"),
        }
        result = chain.invoke(input_data)

        return result
    except Exception:
        return {
            "is_acceptable": True,  # Default to acceptable if check fails
            "issues": [],
            "suggested_corrections": None,
            "confidence": 0.5,
        }


@tool
def analyze_performance_tool(
    student_name: str, total_score: float, max_score: float, percentage: float, questions_summary: str
) -> Dict[str, Any]:
    """
    Analyze overall student performance and identify strengths/weaknesses.
    NOW WITH CONFIDENCE!

    Args:
        student_name: Student's name
        total_score: Total score achieved
        max_score: Maximum possible score
        percentage: Percentage score
        questions_summary: Summary of all question evaluations

    Returns:
        Dictionary with strengths, weaknesses, and confidence
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=settings.GEMINI_API_KEY,
        temperature=0.3,
        max_output_tokens=2048,
    )

    parser = JsonOutputParser(pydantic_object=PerformanceAnalysis)

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """Sen bir eÄŸitim analistisin. Ã–ÄŸrencinin sÄ±nav performansÄ±nÄ± analiz edip gÃ¼Ã§lÃ¼/zayÄ±f yÃ¶nlerini belirle.

Ã–NEMLÄ° KURALLAR:
- Her liste iÃ§in 2-4 madde yaz
- KÄ±sa ve net cÃ¼mleler kullan (maksimum 10-15 kelime)
- TÃ¼rkÃ§e yaz
- Spesifik ol (Ã¶rneÄŸin: "Genel olarak iyi" deÄŸil, "Tarihsel olaylarÄ± kronolojik sÄ±raya koyuyor")
- confidence: Analizine ne kadar gÃ¼veniyorsun? (0-1)

{format_instructions}""",
            ),
            (
                "user",
                """Ã–ÄžRENCÄ° ANALÄ°ZÄ°:
Ã–ÄŸrenci: {student_name}
Toplam Puan: {total_score}/{max_score} (%{percentage})

SORULAR VE CEVAPLAR:
{questions_summary}

GÃ–REV:
YukarÄ±daki sÄ±nav performansÄ±nÄ± analiz ederek Ã¶ÄŸrencinin:
1. GÃœÃ‡LÃœ YÃ–NLERÄ°NÄ° (strengths) - Ne yapÄ±yor iyi? Hangi becerileri gÃ¼Ã§lÃ¼?
2. ZAYIF YÃ–NLERÄ°NÄ° (weaknesses) - Nerelerde zorlanÄ±yor? Hangi eksiklikleri var?
3. CONFIDENCE - Analizine ne kadar gÃ¼veniyorsun?

belirle.""",
            ),
        ]
    )

    chain = (
        {
            "student_name": lambda x: x["student_name"],
            "total_score": lambda x: x["total_score"],
            "max_score": lambda x: x["max_score"],
            "percentage": lambda x: x["percentage"],
            "questions_summary": lambda x: x["questions_summary"],
            "format_instructions": lambda _: parser.get_format_instructions(),
        }
        | prompt
        | llm
        | parser
    )

    try:
        result = chain.invoke(
            {
                "student_name": student_name,
                "total_score": total_score,
                "max_score": max_score,
                "percentage": percentage,
                "questions_summary": questions_summary,
            }
        )

        # Validate structure
        if not isinstance(result.get("strengths"), list):
            result["strengths"] = []
        if not isinstance(result.get("weaknesses"), list):
            result["weaknesses"] = []
        if "confidence" not in result:
            result["confidence"] = 0.8

        return result
    except Exception:
        return {
            "strengths": ["BazÄ± sorulara doÄŸru yanÄ±t verdi"],
            "weaknesses": ["Genel performans dÃ¼ÅŸÃ¼k, daha fazla Ã§alÄ±ÅŸma gerekiyor"],
            "confidence": 0.5,
        }
